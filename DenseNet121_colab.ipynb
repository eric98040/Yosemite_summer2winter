{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fT6X4VWx1YgK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.transforms import autoaugment\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnI7TRni1hY-",
        "outputId": "b8e49c38-ece8-448f-f7c6-76b4a1d0db10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSKCs6u31YgN",
        "outputId": "169210e0-e24e-4f60-bbfe-d2aa7213256b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EJZ79Zh21YgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfbb9d5a-d317-43a3-9f73-36373888ddf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.9.0.80)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.9.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x7oNkOC-1YgQ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
        "from PIL import Image\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "import albumentations as A\n",
        "import albumentations.pytorch\n",
        "\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None, label=0):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.label = label\n",
        "        self.img_paths = [\n",
        "            os.path.join(img_dir, img_file)\n",
        "            for img_file in os.listdir(img_dir)\n",
        "            if img_file.lower().endswith((\"png\", \"jpg\", \"jpeg\"))\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image=np.array(image))['image']\n",
        "        return image, self.label\n",
        "\n",
        "\n",
        "# 이미지 경로\n",
        "root_dir_train = (\n",
        "    \"/content/drive/MyDrive/CDAL/summer2winter_yosemite/train\"\n",
        ")\n",
        "root_dir_test = (\n",
        "    \"/content/drive/MyDrive/CDAL/summer2winter_yosemite/test\"\n",
        ")\n",
        "\n",
        "\n",
        "# 데이터 증강 및 전처리\n",
        "transform_train = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.HorizontalFlip(p=0.85),\n",
        "    A.RandomRotate90(p=0.85),\n",
        "    A.VerticalFlip(p=0.85),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    A.RandomCrop(width=224, height=224),  # 이미지 크기에 맞게 조정 필요\n",
        "    A.OneOf([\n",
        "        A.MotionBlur(p=0.85),\n",
        "        A.OpticalDistortion(p=0.85),\n",
        "        A.GaussNoise(p=0.85)\n",
        "    ], p=0.85),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    A.pytorch.transforms.ToTensorV2(),\n",
        "])\n",
        "\n",
        "\n",
        "transform_test = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    A.pytorch.transforms.ToTensorV2(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hXbFO98e1YgQ"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 생성\n",
        "train_dataset_summer = CustomImageDataset(\n",
        "    os.path.join(root_dir_train, \"train_summer\"), transform=transform_train, label=0\n",
        ")\n",
        "train_dataset_winter = CustomImageDataset(\n",
        "    os.path.join(root_dir_train, \"train_winter\"), transform=transform_train, label=1\n",
        ")\n",
        "\n",
        "test_dataset_summer = CustomImageDataset(\n",
        "    os.path.join(root_dir_test, \"test_summer\"), transform=transform_test, label=0\n",
        ")\n",
        "test_dataset_winter = CustomImageDataset(\n",
        "    os.path.join(root_dir_test, \"test_winter\"), transform=transform_test, label=1\n",
        ")\n",
        "\n",
        "# 데이터셋 합치기\n",
        "train_dataset = ConcatDataset([train_dataset_summer, train_dataset_winter])\n",
        "test_dataset = ConcatDataset([test_dataset_summer, test_dataset_winter])\n",
        "\n",
        "# 검증 데이터셋 분할\n",
        "val_split = 0.2\n",
        "train_size = int((1 - val_split) * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset_split, val_dataset_split = random_split(\n",
        "    train_dataset, [train_size, val_size]\n",
        ")\n",
        "\n",
        "# DataLoader 생성\n",
        "train_loader = DataLoader(train_dataset_split, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset_split, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rWb7WcgS1YgR"
      },
      "outputs": [],
      "source": [
        "# ResNet50 모델 로드 및 수정\n",
        "model = models.densenet121(pretrained=True).to(device)\n",
        "\n",
        "# 모든 파라미터를 먼저 고정하고 특정 레이어의 파라미터를 학습 가능하게 설정\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 마지막 Convolutional Layer의 파라미터\n",
        "params_to_update_conv = []\n",
        "\n",
        "# Fully Connected Layer (Dropout 포함)의 파라미터\n",
        "params_to_update_fc = list(model.classifier.parameters())\n",
        "\n",
        "# DenseNet의 경우 features 블록 내에 denseblock과 transition 레이어가 있으므로, 마지막 denseblock을 Unfreeze\n",
        "if hasattr(model, 'features'):\n",
        "    for param in model.features.denseblock4.parameters():\n",
        "        param.requires_grad = True\n",
        "    params_to_update_conv.extend(model.features.denseblock4.parameters())\n",
        "\n",
        "# DenseNet의 경우\n",
        "num_ftrs = model.classifier.in_features\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(num_ftrs, 2)\n",
        ").to(device)\n",
        "\n",
        "# 전체 파라미터 중 학습할 파라미터만 선택하여 옵티마이저에 전달\n",
        "optimizer = optim.Adam([\n",
        "    {'params': params_to_update_conv, 'lr': 1e-4},  # 마지막 Conv Layer에 대한 학습률\n",
        "    {'params': params_to_update_fc, 'lr': 1e-3}    # FC Layer (Dropout 포함)에 대한 학습률\n",
        "], lr=1e-3)\n",
        "\n",
        "# 스케줄러 설정\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0, last_epoch=-1)\n",
        "\n",
        "\n",
        "# 손실 함수 설정\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 경우 TensorBoard를 설치합니다.\n",
        "!pip install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjfE_nfpDUYL",
        "outputId": "969836a9-8a78-4f98-aa37-503aed888b9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.60.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.25.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# TensorBoard를 위한 SummaryWriter 초기화\n",
        "writer = SummaryWriter('runs/summer2winter_yosemite_experiment')"
      ],
      "metadata": {
        "id": "cpAATyetDWdo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "writer.add_image('train', img_grid)\n",
        "\n",
        "writer.add_graph(model, images.cuda())\n"
      ],
      "metadata": {
        "id": "AIg08IAGdQNp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ec6NInYy1YgS"
      },
      "outputs": [],
      "source": [
        "# 학습 함수\n",
        "def train(model, train_loader, device, criterion, optimizer, epoch, writer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "        train_accuracy = 100. * correct / total\n",
        "\n",
        "        global_step = (epoch - 1) * len(train_loader) + batch_idx\n",
        "        writer.add_scalar('Loss/train', loss.item(), global_step)\n",
        "        writer.add_scalar('Accuracy/train', train_accuracy, global_step)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    print(f'Train Epoch: {epoch}, Loss: {train_loss:.6f}, Acc: {train_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 함수\n",
        "def validate(model, val_loader, device, criterion, epoch, writer):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(val_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "            val_accuracy = 100. * correct / total\n",
        "\n",
        "            global_step = (epoch - 1) * len(val_loader) + batch_idx\n",
        "            writer.add_scalar('Loss/val', loss.item(), global_step)\n",
        "            writer.add_scalar('Accuracy/val', val_accuracy, global_step)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    print(f'Validation Epoch: {epoch}, Loss: {val_loss:.6f}, Acc: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "otohMWNtMh_f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 함수\n",
        "def test(model, device, test_loader, epoch, writer):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_accuracy = 100. * correct / total\n",
        "    print(f'\\nTest set: Accuracy: {test_accuracy:.2f}%\\n')\n",
        "\n"
      ],
      "metadata": {
        "id": "ly0PgXZ9FbH9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnzaJB661YgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04412f51-41df-4079-830b-ddbdf54024e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1, Loss: 0.557671, Acc: 71.95%\n",
            "Validation Epoch: 1, Loss: 0.495232, Acc: 78.59%\n",
            "Train Epoch: 2, Loss: 0.503274, Acc: 75.54%\n",
            "Validation Epoch: 2, Loss: 0.449078, Acc: 79.73%\n"
          ]
        }
      ],
      "source": [
        "# 주어진 설정으로 모델 훈련\n",
        "num_epochs = 50\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(model, train_loader, device, criterion, optimizer, epoch, writer)\n",
        "    validate(model, val_loader, device, criterion, epoch, writer)\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "test(model, device, test_loader, epoch, writer)\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs\n",
        "\n",
        "# 학습이 끝나면 SummaryWriter를 닫음\n",
        "writer.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3TMHrjYfwc64"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
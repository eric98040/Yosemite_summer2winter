{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ne9cE9X3PvcU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E9lZw1IQJ0A",
        "outputId": "0290f468-f455-4999-9b22-24c4ddf8fb9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z2cz6p0LPvcY"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 클래스 정의\n",
        "class ConditionalDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.summer_images = os.listdir(os.path.join(root_dir, 'train_summer'))\n",
        "        self.winter_images = os.listdir(os.path.join(root_dir, 'train_winter'))\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.summer_images), len(self.winter_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < len(self.summer_images):\n",
        "            img_name = os.path.join(self.root_dir, 'train_summer', self.summer_images[idx])\n",
        "            label = 0  # 여름은 라벨 0\n",
        "        else:\n",
        "            img_name = os.path.join(self.root_dir, 'train_winter', self.winter_images[idx % len(self.winter_images)])\n",
        "            label = 1  # 겨울은 라벨 1\n",
        "        image = Image.open(img_name)\n",
        "        if self.transform:\n",
        "        # image를 키워드 인자로 전달\n",
        "            image = np.array(image)  # albumentations는 PIL Image 대신 numpy array를 사용\n",
        "            image = self.transform(image=image)['image']\n",
        "        return image, label\n",
        "\n",
        "\n",
        "\n",
        "# albumentations를 사용한 전처리 정의\n",
        "transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(256, 256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xbWTwqzwPvcZ"
      },
      "outputs": [],
      "source": [
        "# 설정값\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 64\n",
        "epochs = 200\n",
        "nz = 100  # 노이즈 차원\n",
        "lr = 0.0002\n",
        "beta1 = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tX9HzxvyPvcZ"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, num_classes):\n",
        "        super(Generator, self).__init__()\n",
        "        self.nz = nz\n",
        "        self.main = nn.Sequential(\n",
        "            # nz: 잠재 벡터의 크기\n",
        "            # 여기서는 더 깊은 네트워크 구조를 가정\n",
        "            nn.Linear(self.nz, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 128 * 64 * 64),\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm1d(128 * 64 * 64),\n",
        "            nn.Unflatten(1, (128, 64, 64)),\n",
        "            # nn.ConvTranspose2d를 사용하여 이미지를 점진적으로 업샘플링\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 출력: 128 x 128\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),  # 출력: 256 x 256\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(\n",
        "                32, 3, 3, stride=1, padding=1\n",
        "            ),  # 출력 채널을 이미지의 채널 수에 맞게 조정\n",
        "            nn.Tanh(),  # 이미지의 픽셀 값은 -1과 1 사이\n",
        "        )\n",
        "        self.label_emb = nn.Embedding(num_classes, nz)\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        c = self.label_emb(labels)\n",
        "        x = torch.cat([x, c], 1)  # 잠재 벡터 x와 조건 c를 연결\n",
        "        return self.main(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IErNDMT5Pvca"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # 입력 이미지 크기에 맞게 조정\n",
        "            nn.Conv2d(3, 64, 4, stride=2, padding=1),  # 입력: 256 x 256\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 128 x 128\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),  # 64 x 64\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 512, 4, stride=2, padding=1),  # 32 x 32\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),  # 16 x 16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(512, 1, 4, stride=1, padding=0),  # 13 x 13\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(13 * 13, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.label_emb = nn.Embedding(num_classes, 256 * 256 * 3)\n",
        "\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        # 라벨 임베딩을 이미지 텐서와 같은 차원으로 확장\n",
        "        c = self.label_emb(labels)  # 이 부분은 [batch_size, embed_size] 차원을 가짐\n",
        "        c = c.unsqueeze(2).unsqueeze(3)  # [batch_size, embed_size, 1, 1] 형태로 만듦\n",
        "        c = c.repeat(1, 1, x.size(2), x.size(3))  # [batch_size, embed_size, height, width] 차원으로 확장\n",
        "        x = torch.cat([x, c], 1)  # 이미지 텐서 x와 라벨 임베딩 c를 연결\n",
        "        return self.main(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TEJkOFIwPvca"
      },
      "outputs": [],
      "source": [
        "# 데이터셋과 데이터 로더 설정\n",
        "train_dataset = ConditionalDataset(\n",
        "    root_dir='/content/drive/MyDrive/CDAL/summer2winter_yosemite/train', # 또는 train_winter\n",
        "    transform=transform\n",
        ")\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_4nviRf8Pvcb"
      },
      "outputs": [],
      "source": [
        "# 모델 초기화\n",
        "G = Generator(nz, num_classes=2).to(device)\n",
        "D = Discriminator(num_classes=2).to(device)\n",
        "\n",
        "# 손실 함수와 최적화 함수\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(D.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(G.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# 폴더 생성\n",
        "os.makedirs('generated_images', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWLfJptHPvcb",
        "outputId": "084d1d47-fee6-48c1-cb40-e4aa14e9d3f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "\n",
        "# 학습\n",
        "for epoch in range(epochs):\n",
        "    for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
        "        # 실제 데이터에 대한 판별자의 손실 계산\n",
        "        D.zero_grad()\n",
        "        real_images = images.to(device)\n",
        "        b_size = real_images.size(0)\n",
        "        real_label = torch.full((b_size,), 1, device=device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        output = D(real_images, labels).view(-1)\n",
        "        errD_real = criterion(output, real_label)\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        # 가짜 데이터에 대한 판별자의 손실 계산\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        fake_images = G(noise, labels)\n",
        "        fake_label = torch.full((b_size,), 0, device=device)\n",
        "        output = D(fake_images.detach(), labels).view(-1)\n",
        "        errD_fake = criterion(output, fake_label)\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        # 생성자의 손실 계산\n",
        "        G.zero_grad()\n",
        "        output = D(fake_images, labels).view(-1)\n",
        "        errG = criterion(output, real_label)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        # 진행 상황 출력 및 이미지 저장\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, epochs, i, len(train_loader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "            save_image(fake_images, '/content/drive/MyDrive/CDAL/generated_images/epoch_%03d.png' % epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GseaPkJPvcc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 모델 저장\n",
        "torch.save(G.state_dict(), 'generator.pth')\n",
        "torch.save(D.state_dict(), 'discriminator.pth')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
